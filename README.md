# Local LLM Agent for Markdown Files

A Python-based agent that uses Ollama to provide local LLM capabilities for managing and editing markdown files. The agent maintains context of your entire document collection and allows for interactive editing and suggestions.

## Features

- üìù Real-time file monitoring and context updates
- ü§ñ Local LLM integration through Ollama
- ‚ö° Interactive command interface
- üîÑ Automatic context maintenance
- üíæ Backup system for safe editing
- ‚öôÔ∏è Configurable through YAML

## Prerequisites

- Python 3.8 or higher
- [Ollama](https://ollama.ai) installed and running
- Llama 2 model pulled in Ollama

## Installation

1. Install Poetry (package manager):
```bash
curl -sSL https://install.python-poetry.org | python3 -
```

2. Clone the repository:
```bash
git clone <your-repo-url>
cd local_agent
```

3. Install dependencies:
```bash
poetry install
```

4. Install the Llama model in Ollama:
```bash
ollama pull llama3.2
```

## Usage

1. Start Ollama:
```bash
nohup sh -c 'OLLAMA_HOST=127.0.0.1:11435 ollama serve' > ollama.log 2>&1 &
```

2. Run the agent:
```bash
poetry run python agent.py
```

### Available Commands

- `edit <filename>`: Enter edit mode for a specific file
- `context`: Show current document context
- `refresh`: Reload all documents
- `status`: Show current configuration and status
- `exit`: Quit the application

### Edit Mode Commands

When in edit mode (`edit <filename>`):
- `suggest`: Get improvement suggestions from Llama
- `review`: Review current file content
- `save`: Save changes
- `exit`: Exit edit mode

## Configuration

Configuration is stored in `.llama/config.yaml`:

```yaml
model:
  name: llama2
  context_window: 4096
  temperature: 0.7

paths:
  exclude:
    - ".obsidian/*"
    - ".git/*"
  watch_extensions:
    - ".md"

editing:
  backup: true
  backup_dir: ".llama/backups"
  require_approval: true
```

## Project Structure

```
local_agent/
‚îú‚îÄ‚îÄ .llama/
‚îÇ   ‚îî‚îÄ‚îÄ config.yaml     # Configuration file
‚îú‚îÄ‚îÄ docs/              # Your markdown files
‚îú‚îÄ‚îÄ agent.py          # Main application
‚îî‚îÄ‚îÄ README.md         # This file
```

## Development

This project uses Poetry for dependency management. To set up the development environment:

1. Install development dependencies:
```bash
poetry install --with dev
```

2. Activate the virtual environment:
```bash
poetry shell
```

## Contributing

1. Fork the repository
2. Create your feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## License

[MIT License](LICENSE)

## Troubleshooting

### Common Issues

1. **Ollama Connection Error**
   - Ensure Ollama is running (`ollama serve`)
   - Check if the Llama model is installed (`ollama list`)

2. **File Monitoring Issues**
   - Check file permissions
   - Verify paths in config.yaml

3. **Python SSL Error**
   - If you encounter SSL errors, ensure you're using Poetry's virtual environment

### Getting Help

- Open an issue in the repository
- Check the Ollama documentation
- Review the Poetry documentation

## Todo / Roadmap

- [ ] Add support for multiple LLM models
- [ ] Implement concurrent file processing
- [ ] Add web interface
- [ ] Improve diff visualization
- [ ] Add support for custom prompts